{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"kIXJa3ZSbrPh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666196930945,"user_tz":-480,"elapsed":42675,"user":{"displayName":"Mike Lyu","userId":"06712784976026336234"}},"outputId":"bbb7dfd5-7f6b-43a9-f240-e8d9c86ef3b4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Password for user ‘zlyuac’: \n","--2022-10-19 16:28:16--  https://course.cse.ust.hk/comp2211/assignments/pa1/data/20ng_train_dataset.npz\n","Resolving course.cse.ust.hk (course.cse.ust.hk)... 143.89.41.176\n","Connecting to course.cse.ust.hk (course.cse.ust.hk)|143.89.41.176|:443... connected.\n","HTTP request sent, awaiting response... 401 Unauthorized\n","Authentication selected: Basic realm=\"Enter Your CSD PC/Unix Password\"\n","Reusing existing connection to course.cse.ust.hk:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 3253235 (3.1M)\n","Saving to: ‘20ng_train_dataset.npz.2’\n","\n","20ng_train_dataset. 100%[===================>]   3.10M  2.10MB/s    in 1.5s    \n","\n","2022-10-19 16:28:19 (2.10 MB/s) - ‘20ng_train_dataset.npz.2’ saved [3253235/3253235]\n","\n","Password for user ‘zlyuac’: \n","--2022-10-19 16:28:27--  https://course.cse.ust.hk/comp2211/assignments/pa1/data/20ng_test_dataset.npz\n","Resolving course.cse.ust.hk (course.cse.ust.hk)... 143.89.41.176\n","Connecting to course.cse.ust.hk (course.cse.ust.hk)|143.89.41.176|:443... connected.\n","HTTP request sent, awaiting response... 401 Unauthorized\n","Authentication selected: Basic realm=\"Enter Your CSD PC/Unix Password\"\n","Reusing existing connection to course.cse.ust.hk:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 811911 (793K)\n","Saving to: ‘20ng_test_dataset.npz.1’\n","\n","20ng_test_dataset.n 100%[===================>] 792.88K   750KB/s    in 1.1s    \n","\n","2022-10-19 16:28:29 (750 KB/s) - ‘20ng_test_dataset.npz.1’ saved [811911/811911]\n","\n","Password for user ‘zlyuac’: \n","--2022-10-19 16:28:40--  https://course.cse.ust.hk/comp2211/assignments/pa1/data/20ng_train_labels.npy\n","Resolving course.cse.ust.hk (course.cse.ust.hk)... 143.89.41.176\n","Connecting to course.cse.ust.hk (course.cse.ust.hk)|143.89.41.176|:443... connected.\n","HTTP request sent, awaiting response... 401 Unauthorized\n","Authentication selected: Basic realm=\"Enter Your CSD PC/Unix Password\"\n","Reusing existing connection to course.cse.ust.hk:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 54408 (53K)\n","Saving to: ‘20ng_train_labels.npy’\n","\n","20ng_train_labels.n 100%[===================>]  53.13K   128KB/s    in 0.4s    \n","\n","2022-10-19 16:28:41 (128 KB/s) - ‘20ng_train_labels.npy’ saved [54408/54408]\n","\n","Password for user ‘zlyuac’: \n","--2022-10-19 16:28:48--  https://course.cse.ust.hk/comp2211/assignments/pa1/data/20ng_test_labels.npy\n","Resolving course.cse.ust.hk (course.cse.ust.hk)... 143.89.41.176\n","Connecting to course.cse.ust.hk (course.cse.ust.hk)|143.89.41.176|:443... connected.\n","HTTP request sent, awaiting response... 401 Unauthorized\n","Authentication selected: Basic realm=\"Enter Your CSD PC/Unix Password\"\n","Reusing existing connection to course.cse.ust.hk:443.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 15204 (15K)\n","Saving to: ‘20ng_test_labels.npy’\n","\n","20ng_test_labels.np 100%[===================>]  14.85K  71.5KB/s    in 0.2s    \n","\n","2022-10-19 16:28:50 (71.5 KB/s) - ‘20ng_test_labels.npy’ saved [15204/15204]\n","\n"]}],"source":["!wget --user=zlyuac --ask-password https://course.cse.ust.hk/comp2211/assignments/pa1/data/20ng_train_dataset.npz\n","!wget --user=zlyuac --ask-password https://course.cse.ust.hk/comp2211/assignments/pa1/data/20ng_test_dataset.npz\n","!wget --user=zlyuac --ask-password https://course.cse.ust.hk/comp2211/assignments/pa1/data/20ng_train_labels.npy\n","!wget --user=zlyuac --ask-password https://course.cse.ust.hk/comp2211/assignments/pa1/data/20ng_test_labels.npy"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"HOecfRzAddGM","executionInfo":{"status":"ok","timestamp":1666196935159,"user_tz":-480,"elapsed":416,"user":{"displayName":"Mike Lyu","userId":"06712784976026336234"}}},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","source":["class NaiveBayesClassifier:\n","  def __init__(self, train_dataset, test_dataset, train_labels, test_labels):\n","    self.train_dataset = train_dataset\n","    self.test_dataset = test_dataset\n","    self.train_labels = train_labels\n","    self.test_labels = test_labels\n","\n","  def build_training_delta_matrix(self):\n","    #TODO\n","    deltas = np.zeros((self.train_dataset.shape[0],np.amax(self.train_labels)+1))\n","    #number of samples rows, number of classes cols\n","    for i in range(self.train_dataset.shape[0]):\n","       deltas[i][self.train_labels[i]] = 1 \n","    return deltas\n","\n","  def estimate_class_probabilities(self):\n","    #TODO\n","    delta = self.build_training_delta_matrix()\n","    numerator = 1 + np.sum(delta,axis = 0)\n","    denominator = np.amax(self.train_labels)+1 + self.train_dataset.shape[0]\n","    class_prob = numerator / denominator\n","    return class_prob\n","\n","  def estimate_word_probabilities(self):\n","    #TODO\n","    #word_prob: size of voca rows, number of classes cols\n","    delta = self.build_training_delta_matrix()\n","    # (dataset)number of documents rows, size of voca cols,element(Xik,frequency of a word in a document)\n","    numerator = 1 + self.train_dataset.T @ delta #for one class, sum of frequency of a word in all documents.\\\n","    # size: size of voca * num of classes\n","\n","    #sum of frequency of all words, in one class\n","    denominator = self.train_dataset.shape[1] + np.sum(self.train_dataset.T @ delta, axis = 0)\n","\n","    word_prob = numerator / denominator\n","    return word_prob\n","\n","  def predict(self):\n","    #TODO\n","    log_word_prob = np.log(self.estimate_word_probabilities())\n","    temp = np.log(self.estimate_class_probabilities()) + np.sum(self.train_dataset @ log_word_prob, axis = 1)\n","    test_predict = np.amax(temp, axis = 1)\n","    return test_predict"],"metadata":{"id":"6HXqFVhKrJUx","executionInfo":{"status":"ok","timestamp":1666196936727,"user_tz":-480,"elapsed":341,"user":{"displayName":"Mike Lyu","userId":"06712784976026336234"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["  def generate_confusion_matrix(test_predict, test_labels):\n","    #TODO\n","    TP = np.zeros(np.amax(test_predict) + 1)\n","    for i in range(np.amax(test_predict)):\n","      TP = np.count(test_labels[test_predict == i] == test_predict) \n","      TN = np.count(test_labels[test_predict == i] != test_predict)\n","      FP = np.count(test_predict[test_labels != i] == i)\n","      FN = np.count(test_predict[test_labels == i] != i)\n","    return TP, TN, FP, FN"],"metadata":{"id":"bxN0GOiKnSXo","executionInfo":{"status":"ok","timestamp":1666196940124,"user_tz":-480,"elapsed":573,"user":{"displayName":"Mike Lyu","userId":"06712784976026336234"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["  def calculate_precision(test_predict, test_labels, self):\n","    #TODO\n","    TP, TN, FP, FN = self.generate_confusion_matrix(test_predict, test_labels)\n","    numerator = np.sum(TP)\n","    demoninator = np.sum(TP + FP)\n","    precision = numerator / demoninator\n","    return precision"],"metadata":{"id":"g1qmmiLxkSym","executionInfo":{"status":"ok","timestamp":1666196941327,"user_tz":-480,"elapsed":2,"user":{"displayName":"Mike Lyu","userId":"06712784976026336234"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["  def calculate_recall(test_predict, test_labels, self):\n","    #TODO\n","    TP, TN, FP, FN = self.generate_confusion_matrix(test_predict, test_labels)\n","    numerator = np.sum(TP)\n","    demoninator = np.sum(TP + FN)\n","    recall = numerator / demoninator\n","    return recall"],"metadata":{"id":"vXnCv7wltW8F","executionInfo":{"status":"ok","timestamp":1666196943719,"user_tz":-480,"elapsed":295,"user":{"displayName":"Mike Lyu","userId":"06712784976026336234"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["  def calculate_micro_f1(test_predict, test_labels, self):\n","    #TODO\n","    p = self.calculate_precision(test_predict, test_labels)\n","    R = self.calculate_recall(test_predict, test_labels)\n","    micro_f1 = 2 * P * R / (P + R)\n","    return micro_f1"],"metadata":{"id":"aUzw0yckuFcs","executionInfo":{"status":"ok","timestamp":1666196945900,"user_tz":-480,"elapsed":311,"user":{"displayName":"Mike Lyu","userId":"06712784976026336234"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","execution_count":8,"metadata":{"id":"kMN8ZPen8JKW","executionInfo":{"status":"ok","timestamp":1666196949269,"user_tz":-480,"elapsed":2,"user":{"displayName":"Mike Lyu","userId":"06712784976026336234"}}},"outputs":[],"source":["  def calculate_macro_f1(test_predict, test_labels, self):\n","    #TODO\n","    num_classes = np.amax(self.train_labels)\n","    num_test_documents = train_dataset.shape[0]\n","    TP, TN, FP, FN = self.generate_confusion_matrix(test_predict, test_labels)\n","    R, P = np.zeros(num_test_documents, num_classes)\n","    R = TP / (TP + FN)\n","    P = TP / (TP + FN)\n","    macro_f1 = 1/num_classes * np.sum(2 * P * R / (P + R))\n","    return macro_f1"]},{"cell_type":"markdown","metadata":{"id":"9DX2HK_KDwW1"},"source":["# Optional Task: Test Run\n","Use all the previously defined functions in Tasks 1 and 2 to perform the Naive Bayes text classifier on our 20 Newsgroups dataset. Feel free to modify this code cell for your own testing and debugging purposes, which will not be graded."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"X6ZDDEPLEGgh","executionInfo":{"status":"ok","timestamp":1666196957496,"user_tz":-480,"elapsed":5679,"user":{"displayName":"Mike Lyu","userId":"06712784976026336234"}}},"outputs":[],"source":["import scipy.sparse as sparse\n","\n","if __name__ == '__main__':\n","  train_dataset = sparse.load_npz(\"20ng_train_dataset.npz\")\n","  test_dataset = sparse.load_npz(\"20ng_test_dataset.npz\")\n","  train_dataset = train_dataset.toarray()\n","  test_dataset = test_dataset.toarray()\n","  train_labels = np.load(\"20ng_train_labels.npy\")\n","  test_labels = np.load(\"20ng_test_labels.npy\")\n","\n","  #TODO Optional"]},{"cell_type":"markdown","metadata":{"id":"LL7aL_Q_DZFM"},"source":["# References\n","Kamal Nigam, Andrew McCallum, and Tom Mitchell. 2006. Semi-supervised text classification using EM. Semi-Supervised Learning (2006), 33–56."]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}